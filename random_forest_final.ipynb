{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN VGG16 Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models_flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(2017) \n",
    "\n",
    "#Keras, deep learning libraries\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from scipy import misc\n",
    "import skimage.transform as st\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import h5py\n",
    "from flask import Flask, request, render_template\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Function for model evaluation### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot model accuracy and loss function\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute test accuracy\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=0)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sophia/Desktop/CMPE 257/Project/code'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "TRAIN_DATADIR = '/Users/sophia/Desktop/Train_2'\n",
    "TEST_DATADIR = '/Users/sophia/Desktop/Test_2'\n",
    "CATEGORIES = [\"GreyPowder\", \"GrayMold\", \"MosaicVirus\", \"Healthy\"]\n",
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalized data\n",
    "    \"\"\"\n",
    "    return np.array((x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "\n",
    "def create_data(data_directory):\n",
    "    _data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(data_directory, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread((os.path.join(path, img)), cv2.IMREAD_COLOR)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                _data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(_data)\n",
    "    return _data\n",
    "\n",
    "\n",
    "def pickle_training_data(is_pickle=False):\n",
    "    training_data = create_data(TRAIN_DATADIR)\n",
    "    X_train, y_train = [], []\n",
    "    for features, label in training_data:\n",
    "        X_train.append(features)\n",
    "        y_train.append(label)\n",
    "\n",
    "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    X_train = normalize(X_train)\n",
    "\n",
    "    if is_pickle:\n",
    "        pickle_out = open(\"X_train.pickle\", \"wb\")\n",
    "        pickle.dump(X_train, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        pickle_out = open(\"y_train.pickle\", \"wb\")\n",
    "        pickle.dump(y_train, pickle_out)\n",
    "        pickle_out.close()\n",
    "    else:\n",
    "        return X_train, y_train\n",
    "\n",
    "\n",
    "def pickle_test_data(is_pickle=False):\n",
    "    training_data = create_data(TEST_DATADIR)\n",
    "    X_test, y_test = [], []\n",
    "    for features, label in training_data:\n",
    "        X_test.append(features)\n",
    "        y_test.append(label)\n",
    "\n",
    "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    X_test = normalize(X_test)\n",
    "\n",
    "    if is_pickle:\n",
    "        pickle_out = open(\"X_test.pickle\", \"wb\")\n",
    "        pickle.dump(X_test, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        pickle_out = open(\"y_test.pickle\", \"wb\")\n",
    "        pickle.dump(y_test, pickle_out)\n",
    "        pickle_out.close()\n",
    "    else:\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = pickle_training_data()\n",
    "X_test, y_test = pickle_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (16648, 224, 224, 3)\n",
      "y (16648,)\n",
      "X_test (4683, 224, 224, 3)\n",
      "y_test (4683,)\n"
     ]
    }
   ],
   "source": [
    "#explore dataset\n",
    "print('X', X.shape)\n",
    "print('y', np.array(y).shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing images for each class in the dataset\n",
    "# class_names = ['Healthy','Mosaic_Virus','Gray_Mold','Gray_Powdery','Bipolaris']\n",
    "# print(f\"number of target classes : {num_classes}\")\n",
    "\n",
    "# fig = plt.figure(figsize=(8,3))\n",
    "# for i in range(num_classes):\n",
    "#     ax = fig.add_subplot(1, 5, 1 + i, xticks=[], yticks=[])\n",
    "#     idx = np.where(data_labels[:]==i)[0]\n",
    "#     features_idx = data_features[idx,::]\n",
    "#     img_num = np.random.randint(features_idx.shape[0])\n",
    "#     im = np.transpose(features_idx[img_num,::], (0,1,2))\n",
    "#     ax.set_title(class_names[i])\n",
    "#     plt.imshow(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sklearn.tree as tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the parameter grid\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [15,20,25,30,50],\n",
    "    'n_estimators': [90,100,200,300,400,500]\n",
    "}\n",
    "rf_1 = RandomForestClassifier(random_state=0, verbose=1, n_jobs=3)\n",
    "grid_search = GridSearchCV(estimator=rf_1, param_grid=param_grid, cv=3)\n",
    "#fit the grid search to the data\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the hyper-parameter tuning\n",
    "def class_plot(grid, grid_param, title):\n",
    "    scores = [x for x in grid.cv_results_['mean_test_score']]\n",
    "    m_depth = grid_param['max_depth']\n",
    "    n_est = grid_param['n_estimators']\n",
    "    scores = np.array(scores).reshape(len(m_depth), len(n_est))\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for ind, i in enumerate(m_depth):\n",
    "        plt.plot(n_est, scores[ind], '-o', label='Max depth' + str(i),)\n",
    "    ax.legend(loc='lower right') #, bbox_to_anchor=(1, 0.5))\n",
    "    plt.xlabel('n estimator')\n",
    "    plt.ylabel('Mean score')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_plot(grid_search,param_grid,\"Grid Search Result\")\n",
    "print (grid_search_2.best_params_)\n",
    "print (grid_search_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train the model with full training set\n",
    "rf_best = grid_search.best_estimator_\n",
    "rf_best.fit(X, y)\n",
    "y_predict = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test, y_predict)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(matrix,annot=True, annot_kws={'size':10},cmap=plt.cm.Greens,linewidths=0.1)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Healthy', 'MosaicVirus','GrayMold','GrayPowdery']\n",
    "tick_marks = np.arange(len(class_names)+1)\n",
    "#tick_marks2 = tick_marks  + 0.1\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\\n\",accuracy_score(y_test, y_predict),\"\\n\")\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_predict),\"\\n\")\n",
    "\n",
    "print(\"Classification Report:\\n\",classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from ipywidgets import interactive, IntSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {'Healthy':0, 'Mosaic_Virus':1,'Gray_Mold':2,'Gray_Powdery':3}\n",
    "y_train_num = pd.Series( [class_names[label] for label in y_train])\n",
    "y_test_num = pd.Series( [class_names[label] for label in y_test])\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "f_list = [x for x in range(2352)]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf_1.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf_1.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = f_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')\n",
    "\n",
    "import graphviz\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "src = graphviz.Source(dot_graph)\n",
    "src.render('test-output.gv', view=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
